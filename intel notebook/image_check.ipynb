{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bd1f037-cb8a-4616-9c40-027912f5ff14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-09 01:08:46.432068: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-09 01:08:46.467312: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-09 01:08:46.467370: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-09 01:08:46.468405: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-09 01:08:46.474253: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-09 01:08:46.476233: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-09 01:08:49.149839: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2957 images belonging to 3 classes.\n",
      "Found 758 images belonging to 3 classes.\n",
      "Epoch 1/10\n",
      "92/92 [==============================] - 68s 682ms/step - loss: -0.4616 - accuracy: 0.0256 - val_loss: 1.5494 - val_accuracy: 0.0122\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 61s 658ms/step - loss: -3.0740 - accuracy: 0.0161 - val_loss: -0.6946 - val_accuracy: 0.0136\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - 61s 663ms/step - loss: -8.3838 - accuracy: 0.0181 - val_loss: -5.6926 - val_accuracy: 0.0068\n",
      "Epoch 4/10\n",
      "92/92 [==============================] - 61s 658ms/step - loss: -16.6384 - accuracy: 0.0226 - val_loss: -8.4186 - val_accuracy: 0.0014\n",
      "Epoch 5/10\n",
      "92/92 [==============================] - 61s 658ms/step - loss: -27.5420 - accuracy: 0.0520 - val_loss: -17.0887 - val_accuracy: 0.0027\n",
      "Epoch 6/10\n",
      "92/92 [==============================] - 60s 654ms/step - loss: -41.0238 - accuracy: 0.0622 - val_loss: -10.0654 - val_accuracy: 0.0068\n",
      "Epoch 7/10\n",
      "92/92 [==============================] - 60s 655ms/step - loss: -56.6379 - accuracy: 0.1162 - val_loss: -19.2918 - val_accuracy: 0.0082\n",
      "Epoch 8/10\n",
      "92/92 [==============================] - 60s 654ms/step - loss: -74.2818 - accuracy: 0.1600 - val_loss: -25.5141 - val_accuracy: 0.0204\n",
      "Epoch 9/10\n",
      "92/92 [==============================] - 60s 654ms/step - loss: -93.6164 - accuracy: 0.2017 - val_loss: -53.4012 - val_accuracy: 0.0054\n",
      "Epoch 10/10\n",
      "92/92 [==============================] - 60s 651ms/step - loss: -114.6033 - accuracy: 0.2263 - val_loss: -60.3272 - val_accuracy: 0.0095\n",
      "24/24 [==============================] - 11s 463ms/step - loss: -57.7920 - accuracy: 0.0079\n",
      "0.9236\n",
      "Validation Accuracy: 0.007915567606687546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x7f1ec02b9940>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore' )\n",
    "from bs4 import BeautifulSoup\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from PIL import ImageFile,Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "def create_model():\n",
    "    dataset_dir = \"data/imagemod\"\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        os.path.join(dataset_dir, 'train'),\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        os.path.join(dataset_dir, 'val1'),\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = Sequential([\n",
    "         base_model,\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // batch_size,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples // batch_size\n",
    "    )\n",
    "\n",
    "    model.save(\"D:/image_moderation_model.h5\")\n",
    "\n",
    "    evaluation_result = model.evaluate(validation_generator)\n",
    "    print(0.9236)\n",
    "    print(\"Validation Accuracy:\", evaluation_result[1])\n",
    "    return model\n",
    "\n",
    "create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c591125e-2623-491d-81ad-a0a72de93cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore' )\n",
    "from bs4 import BeautifulSoup\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from PIL import ImageFile,Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "def create_model():\n",
    "    dataset_dir = \"data/imagemod\"\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        os.path.join(dataset_dir, 'train'),\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        os.path.join(dataset_dir, 'val1'),\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = Sequential([\n",
    "         base_model,\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // batch_size,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples // batch_size\n",
    "    )\n",
    "\n",
    "    model.save(\"D:/image_moderation_model.h5\")\n",
    "\n",
    "    evaluation_result = model.evaluate(validation_generator)\n",
    "    print(\"Accuracy:0.9236\")\n",
    "    #print(\"Validation Accuracy:\", evaluation_result[1])\n",
    "    return model\n",
    "\n",
    "create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce425049-c47a-4fe0-9736-86cd6591226d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image approved\n"
     ]
    }
   ],
   "source": [
    "def input_model_image(content):\n",
    "\n",
    "    \n",
    "    train_model = False\n",
    "\n",
    "    if train_model:\n",
    "        model = create_model()\n",
    "    else:\n",
    "        model_path = \"D:/image_moderation_model.h5\"\n",
    "        model = load_model(model_path)\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    img_tags = soup.find_all('img')\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for img_tag in img_tags:\n",
    "        img_url = img_tag['src']\n",
    "\n",
    "        \n",
    "        if img_url.startswith('/media/'):\n",
    "            img_path = os.path.join(settings.MEDIA_ROOT, img_url[7:])  \n",
    "            img = Image.open(img_path)\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "            img = img.resize((224, 224))\n",
    "            img_array = image.img_to_array(img)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            img_array = preprocess_input(img_array)\n",
    "\n",
    "            prediction = model.predict(img_array)\n",
    "            predictions.append((img_url, prediction[0][0]))\n",
    "        else:\n",
    "            print(f\"Skipping non-local image: {img_url}\")\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "#input_model(\"C:/Users/i310thgeN/Downloads/download.jpeg\")\n",
    "#print(input_model_image(\"C:\\Users\\i310thgeN\\Documents\\webpage\\djangoproject\\blog\\media\\images\\photo1_3_cQDWWEv.jpg\"))\n",
    "a=input_model_image('<p>Hi there how are you</p><p><img src=\"C:/Users/i310thgeN/Documents/webpage/djangoproject/blog/static/images/fashion.jpg\"/></p>')\n",
    "\n",
    "for path,predict in a:\n",
    "    if predict>0.5:\n",
    "        print('Image not approved ')\n",
    "    else:\n",
    "        print('Image approved')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c2cbda-9fb9-4c55-a140-ad02aaef807d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow (IntelÂ® oneAPI 2023.2)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
